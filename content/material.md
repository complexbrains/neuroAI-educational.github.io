# Material

(material:supervised_learning)=
## Supervised learning using scikit-learn

### Instructor
::::{card-carousel} 3
:::{card} Nikhil Bhagwat
:margin: 3
:class-body: text-center
:link: https://github.com/nikhil153
:img-top: https://avatars.githubusercontent.com/u/7978607?v=4
:::
::::

**Nikhil Bhagwat, PhD** is an Academic Associate in the [ORIGAMI lab](https://neurodatascience.github.io/) (PI: [Dr. JB Poline](https://www.mcgill.ca/neuro/jean-baptiste-poline-phd)) at McGill University. He completed his PhD thesis on prognostic applications for Alzheimer’s disease using MR imaging and machine-learning (ML) techniques in the [CoBrA Lab](https://www.cobralab.ca/) (PI: [Dr. Mallar Chakravarty](http://cobralab.ca/members/commander/)) at the University of Toronto. Subsequently, he worked as a researcher at the University of Massachusetts and the Allen Institute. His current research interests include disease staging, subtyping, and prognosis using ML models, along with development of neuroinformatics tools for improving [reproducibility](https://github.com/neurodatascience/mr_proc) and [sustainability](https://neuropipelines.github.io/10carbon) of computational pipelines.

### Objectives
  * Define machine-learning nomenclature
  * Describe basics of the “learning” process
  * Explain model design choices and performance trade-offs
  * Introduce model selection and validation frameworks
  * Explain model performance metrics

### Questions you will be able to answer after taking this module:
  * Model training - what is under/over-fitting?
  * Model selection - what is (nested) cross-validation?
  * Model evaluatation - what are type-1 and type-2 errors?

### Materials
::::{card-carousel} 3
:::{card}
:margin: 3
:class-body: text-center
:class-header: bg-light text-center
:link: https://youtu.be/bnIH84oYRnE
**Video of this session**
^^^
```{image} images/logo_youtube.png
:height: 100
```
+++
Get to the session {fas}`arrow-right`
:::

:::{card}
:margin: 3
:class-body: text-center
:class-header: bg-light text-center
:link: https://github.com/neurodatascience/main-2021-ml-parts-1-2

**The session's repository**
^^^
```{image} https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png
:height: 100
```

Check out the session's materials on `GitHub`.
+++
Explore {fas}`arrow-right`
:::
::::

## Representational structure in neural time series using calcium imaging and electrophysiology

### Instructors
::::{card-carousel} 3
:::{card} Giuseppe Pietro Gava
:margin: 3
:class-body: text-center
:link: https://www.linkedin.com/in/giuseppe-pietro-gava/
:img-top: images/profile_giuseppe.jpg
:::

:::{card} Quinn Lee
:margin: 3
:class-body: text-center
:link: https://www.linkedin.com/in/j-quinn-lee-142a8984
:img-top: images/profile_quinn.jpg
:::
::::

**Quinn Lee, PhD** is a CIHR/FRQ postdoctoral research fellow in the Brandon Lab at McGill University (Montreal, QC, Canada). Prior to joining the Brandon Lab, he completed my PhD at the University of Lethbridge (Lethbridge, AB, Canada) with Drs. Robert Sutherland and Robert McDonald studying how long-term memory is organized at the systems-level in the brain. His current work aims to understand how aspects of experience and memory are represented in neuronal population activity in the rodent hippocampus across protracted experience. To this end, he uses a combination of miniscope calcium imaging in freely moving animals, advanced behavioral tracking, and computational methods to explore questions about neuronal representation and behavior.

**Giuseppe P Gava, PhD** is a postdoctoral neuroscientist in the Dupret Lab at the MRC BNDU, University of Oxford. He was awarded a PhD from the Centre for Doctoral Training in Neurotechnology at Imperial College London, where he also graduated in Biomedical Engineering. He aims to use concepts from network science, topology and information theory to understand the complex neural circuitry and dynamics that shape memory and cognition.

### Objectives
 * Data analysis for electrophysiological time series from freely-behaving animals
 * Data analysis for in vivo calcium imaging time series from freely-behaving animals
 * Assess the co-firing structure and topology of neuronal networks, comparing them using Riemannian metrics
 * Compare representation in neural data to theoretical models with representational similarity analysis (RSA) and manifold-based analyses


### Materials

 ::::{card-carousel} 4

 :::{card}
 :margin: 3
 :class-body: text-center
 :class-header: bg-light text-center
 :link: https://youtu.be/CwEkt4WhtQE
 **Video of this session**
 ^^^
 ```{image} images/logo_youtube.png
 :height: 100
 ```
 +++
 Get to the session {fas}`arrow-right`
 :::

 :::{card}
 :margin: 3
 :class-body: text-center
 :class-header: bg-light text-center
 :link: https://github.com/drsax93/cofiringTopology

 **Ephys session's repository**
 ^^^
 ```{image} https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png
 :height: 100
 ```

 Check out the session's materials on `GitHub`.
 +++
 Explore {fas}`arrow-right`
 :::

 :::{card}
 :margin: 3
 :class-body: text-center
 :class-header: bg-light text-center
 :link: https://colab.research.google.com/drive/1eQjaabGHZFHwYjiM516S0UjeL9B3-2iZ#scrollTo=Rvuf55uzAKXn

 **Ephys session's notebook**
 ^^^
 ```{image} images/logo_colab.png
 :height: 100
 ```

 Check out the session's materials on `Google Colab`.
 +++
 Explore the notebook {fas}`arrow-right`
 :::

 :::{card}
 :margin: 3
 :class-body: text-center
 :class-header: bg-light text-center
 :link: https://github.com/jquinnlee/MAIN_2022_calRSA/blob/main/MAIN2022_calciumRSA_demo.ipynb

 **Calcium imaging session's repository**
 ^^^
 ```{image} https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png
 :height: 100
 ```

 Check out the session's materials on `GitHub`.
 +++
 Explore {fas}`arrow-right`
 :::

 ::::

## Keynote: What's the endgame of neuroAI?

::::{card-carousel} 3
:::{card} Patrick Mineault
:margin: 3
:class-body: text-center
:link: https://xcorr.net/about/
:img-top: images/profile_patrick.jpg
:::
::::

**Patrick Mineault, PhD** is a neurotechnologist and CEO of xcorr consulting. His career spans academia and industry: he was a data scientist at Google, research scientist at Meta on brain-computer-interfaces, founder of a medtech startup and founding CTO of the educational nonprofit Neuromatch. His research at the intersection of neuroscience and AI has been published in NeurIPS, Neuron, PNAS, J Neurosci and Plos Comp Bio. He is the author of the Good Research Code Handbook and writes a popular computational neuroscience blog, [xcorr.net](https://xcorr.net/). He obtained his PhD in computational neuroscience at McGill University.

**Summary**: Neuroscience and AI have a long, intertwined history. Artificial intelligence pioneers looked to the principles of the organization of the brain as inspiration to make intelligent machines. In a surprising reversal, AI is now helping us understand its very source of inspiration: the human brain. Over the next decade, we’ll make ever more precise in silico brain models. As a result, we’ll soon be able to download and use sensory models, on demand, with the same convenience that we can do object recognition or natural language processing.

In this talk, I will take you on a tour of the near future. I will argue that we should use this newfound capability to help improve human health, both for people with neurological disorders and to enhance the well. I discuss enabling technological trends: advances in AI, industrial use cases, AR/VR and BCI. I invite everyone to reflect on the role of innovation and academia to help humans flourish.

### Materials

::::{card-carousel} 3

:::{card}
:margin: 3
:class-body: text-center
:class-header: bg-light text-center
:link: https://www.youtube.com/watch?v=-Gci9mkRkEs
**Video of this session**
^^^
```{image} images/logo_youtube.png
:height: 100
```
+++
Get to the session {fas}`arrow-right`
:::
::::

## Introduction to deep learning using Pytorch

### Instructors
::::{card-carousel} 3
:::{card} Mohammad Yaghoubi
:margin: 3
:class-body: text-center
:link: https://www.linkedin.com/in/mohammad-hassan-yaghoubi-496b0aaa
:img-top: images/profile_mohammad.jpg
:::

:::{card} Thomas Jiralerspong
:margin: 3
:class-body: text-center
:link: https://www.linkedin.com/in/thomas-jiralerspong/?originalSubdomain=ca
:img-top: images/profile_thomas.jpg
:::

:::{card} Krystal Pan
:margin: 3
:class-body: text-center
:link: https://www.linkedin.com/in/krystal-xuejing-pan/?originalSubdomain=ca
:img-top: images/profile_krystal.jpg
:::
::::

**Mohammad Yaghoubi** is a PhD student at McGill University. He conducts his research under the supervision of Dr. Mark Brandon at the Integrated Program in Neuroscience. His research focuses on developing statistical and machine-learning based tools to better analyze high-dimensional neuronal and behavioral data.

**Thomas Jiralerspong** is an undergraduate student in Honours Computer Science at McGill. He is also an undergraduate researcher with Professor Blake Richards, interested in generalization in reinforcement learning and cognitively inspired reinforcement learning models.

**Krystal Pan** is a Master’s student under supervision by Dr. Blake Richards. She is interested in biologically plausible AI models of the vision system. She is also the Lab Manager of the LiNC Lab.

### Objectives
 * Understand basic concepts in deep learning
 * Discover the pytorch interface to build artificial neural networks
 * Train a basic model using pytorch

### Materials
The training material is adapted from NeuroMatch Academy. Note that videos recorded by Pr. Konrad Kording are included in the google colab resource. The main educational session was purely hands-on support of the participants, and recording of this session will not be made available.

::::{card-carousel} 3
:::{card}
:margin: 3
:class-body: text-center
:class-header: bg-light text-center
:link: https://colab.research.google.com/drive/1Arf7Ydg1VjNx5wv9IOI5xTCYbQ5Djo-7?usp=sharing

**The session's notebook**
^^^
```{image} images/logo_colab.png
:height: 100
```

Check out the session's materials on `Google Colab`.
+++
Explore the notebook {fas}`arrow-right`
:::
::::

## Machine learning in functional MRI using [Nilearn](https://nilearn.github.io)

### Instructors

::::{card-carousel} 3
:::{card} Yasmin Mzayek
:margin: 3
:class-body: text-center
:link: https://www.linkedin.com/in/yasmin-mzayek-100547134/
:img-top: images/profile_yasmin.jpg
:::

:::{card} Hao-Ting Wang
:margin: 3
:class-body: text-center
:link: https://wanghaoting.com
:img-top: https://avatars.githubusercontent.com/u/13743617?v=4
:::
::::

**Yasmin Mzayek** obtained her Master's in Brain and Cognitive Sciences from the University of Amsterdam. During this time she did an internship at the Netherlands Cancer Institute in Amsterdam and worked on analyzing diffusion-weighted imaging data. Then she went to Aix Marseille University to work on pulse sequence programming for diffusion MR spectroscopy as well as processing and analysis of data from this modality. She also worked as scientific programmer and data scientist at the University of Groningen. Currently, she is a research engineer at INRIA working on maintaining the Nilearn Python toolkit.

**Hao-Ting Wang, PhD** is a IVADO postdoctoral fellow at CRIUGM. Her project focuses on discovery of transdiagnostic brain biomarkers amongst neurodegenerative conditions from multiple open access datasets. Her expertise lies in fMRI data processing, functional connectivity, and data workflow construction. She is also a core developer of Nilearn with a focus on fMRI data processing and feature extraction.

### Objectives
 * Understand the structure of functional magnetic resonance imaging data.
 * Generate correlation matrices using fMRI time series (aka "connectomes").
 * Visualize brain maps and connectomes.
 * Train machine learning models to classify subjects by age groups based on brain connectivity.

### Materials
::::{card-carousel} 3
:::{card}
:margin: 3
:class-body: text-center
:class-header: bg-light text-center
:link: https://www.youtube.com/watch?v=g0y7wpktdjk
**Video of this session**
^^^
```{image} images/logo_youtube.png
:height: 100
```
+++
Get to the session {fas}`arrow-right`
:::

:::{card}
:margin: 3
:class-body: text-center
:class-header: bg-light text-center
:link: https://github.com/main-educational/intro_nilearn

**Session's repository**
^^^
```{image} https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png
:height: 100
```

Check out the session's materials on `GitHub`.
+++
Explore {fas}`arrow-right`
:::

:::{card}
:margin: 3
:class-body: text-center
:class-header: bg-light text-center
:link: https://main-educational.github.io/intro_nilearn/intro.html
**The Jupyter Book of this session**
^^^
```{image} images/logo_neurolibre.png
:height: 100
```

Explore and follow the session via `Jupyter Book`.
+++
Get to the session {fas}`arrow-right`
:::

::::

## Keynote: Aligning representations in brains and machines
::::{card-carousel} 3
:::{card} Elizabeth Dupre
:margin: 3
:class-body: text-center
:link: https://elizabeth-dupre.com/
:img-top: images/profile_emdupre.jpg
:::
::::

**Elizabeth Dupre, PhD** is a [Wu Tsai interdisciplinary postdoctoral research fellow](https://neuroscience.stanford.edu/people/elizabeth-dupre) at Stanford University, working between Prof. Russ [Poldrack](https://poldracklab.stanford.edu/) and Prof. Scott [Linderman](https://web.stanford.edu/~swl1/). As a psychologist and computational neuroscientist, her work focuses on modeling individual brain activity across a range of cognitive states—and assessing the generalizability of these individualized models—by extending statistical methods for human neuroimaging data analysis. Through her work, Dr DuPre has taken an active role developing tools in the open source Python ecosystem, with a focus on improving the reproducibility of analysis workflows.

**Summary**: Computational neuroscience is focused on uncovering general organizational principles supporting neural activity and behavior; however, uncovering these principles relies on making appropriate comparisons across individuals. This presents a core technical and conceptual challenge, as individuals differ along nearly every relevant dimension: from the number of neurons supporting computation to the exact computation being performed. Similarly in artificial neural networks, multiple initializations of the same architecture—on the same data—may recruit non-overlapping hidden units, complicating direct comparisons of trained networks.

In this talk, I will introduce techniques for aligning representations in both brains and in machines. I will argue for the importance of considering alignment methods in developing a comprehensive science at the intersection of artificial intelligence and neuroscience that reflects our shared goal of understanding principles of computation. Finally, I will consider current applications and limitations of these techniques, discussing relevant future directions for this area.

### Materials
::::{card-carousel} 3
:::{card}
:margin: 3
:class-body: text-center
:class-header: bg-light text-center
:link: https://www.youtube.com/watch?v=IWIiR6mjrXY
**Video of this session**
^^^
```{image} images/logo_youtube.png
:height: 100
```
+++
Get to the session {fas}`arrow-right`
:::


:::{card}
:margin: 3
:class-body: text-center
:class-header: bg-light text-center
:link: https://doi.org/10.5281/zenodo.7422545

**The session's slides**
^^^
```{image} images/logo_pdf.png
:height: 100
```

Check out the session's slides on `zenodo`.
+++
Explore {fas}`arrow-right`
:::
::::

## Model selection and validation

### Instructor
::::{card-carousel} 3
:::{card} Jérôme Dockès
:margin: 3
:class-body: text-center
:link: https://github.com/jeromedockes
:img-top: images/profile_jerome.jpg
:::
::::

**Jérôme Dockès** is a post-doc in the [ORIGAMI lab](https://neurodatascience.github.io/) (PI: [Dr. JB Poline](https://www.mcgill.ca/neuro/jean-baptiste-poline-phd)) at McGill University.
He completed his PhD thesis on statistical methods for large-scale meta-analysis of neuroimaging studies in the [Parietal lab](https://team.inria.fr/parietal/) at INRIA.
His current work focuses on tools and resources to facilitate text-mining and meta-analysis of the neuroimaging literature.

### Objectives
 * Understand how to evaluate the performance of machine learning models.
 * Learn about hyperparameters and model selection.
 * Learn about pitfalls when validating machine learning models and how to easily avoid them using scikit-learn.

### Materials
::::{card-carousel} 3
:::{card}
:margin: 3
:class-body: text-center
:class-header: bg-light text-center
:link: https://youtu.be/X7RBbD__MJw
**Video of this session**
^^^
```{image} images/logo_youtube.png
:height: 100
```
+++
Get to the session {fas}`arrow-right`
:::

:::{card}
:margin: 3
:class-body: text-center
:class-header: bg-light text-center
:link: https://github.com/neurodatascience/main-2021-ml-parts-1-2

**The session's GitHub repository**
^^^
```{image} https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png
:height: 100
```

Check out the session's materials on `GitHub`.
+++
Explore the `GitHub` repository {fas}`arrow-right`
:::
::::

## Machine learning on electro- and magneto-encephalography (EEG/MEG)

### Instructor
::::{card-carousel} 3
:::{card} Alex Gramfort
:margin: 3
:class-body: text-center
:link: https://alexandre.gramfort.net/
:img-top: https://alexandre.gramfort.net/images/picture3.jpg
:::

:::{card} Hubert Banville
:margin: 3
:class-body: text-center
:link: https://github.com/hubertjb
:img-top: https://hubertjb.github.io/images/me.jpg
:::
::::

**Alex Gramfort** is a research scientist at Meta in Paris, France. Before joining Meta, he was a team leader and PI at Inria. His work focusses on machine learning for brain signals. His main and active opensource contributions are to [scikit-learn](https://scikit-learn.org), [MNE-Python](https://mne.tools/stable/index.html) and [braindecode](https://braindecode.org/stable/index.html).

**Hubert Banville** is a Research Scientist at InteraXon (maker of the Muse headband). He completed a PhD in the Parietal team at Inria, Université Paris-Saclay, under the supervision of Alexandre Gramfort and Denis Engemann. This work was done jointly at InteraXon. His research focuses on machine learning for processing EEG and other biosignals.

### Objectives
 * Understand the structure of electro- and magneto-encephalography signals
 * Preprocess and visualize MEG/EEG data
 * Learn about the ML techniques to decode evoked and induced MEG/EEG activity
 * Train machine learning models on MEG data using [MNE-python](https://mne.tools/stable/index.html) and PyTorch

### Materials
::::{card-carousel} 3
:::{card}
:margin: 3
:class-body: text-center
:class-header: bg-light text-center
:link: https://www.youtube.com/watch?v=ePrxz7wRp1g
**Video of this session**
^^^
```{image} images/logo_youtube.png
:height: 100
```
+++
Get to the session {fas}`arrow-right`
:::

:::{card}
:margin: 3
:class-body: text-center
:class-header: bg-light text-center
:link: https://github.com/agramfort/22_main_ml_meeg_tuto

**The session's GitHub repository**
^^^
```{image} https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png
:height: 100
```

Check out the session's materials.
+++
Explore {fas}`arrow-right`
:::
::::


## Brain decoding

Within this session, we will go through the basics of running/applying `decoding models`
to `fMRI` data. More precisely, we will explore how we can utilize different `decoding models`
to `estimate`/`predict` what an agent is `perceiving` or `doing` based on `recordings` of `responses`/`activity`.
Given the time restrictions, we will focus on `biological agents`, ie `human participants`, and thus `brain` `responses` obtained from `fMRI`.
### Instructors
::::{card-carousel} 4
:::{card} Peer Herholz
:margin: 1
:class-body: text-center
:link: https://github.com/PeerHerholz
:img-top: https://avatars.githubusercontent.com/u/20129524?v=4?s=100
:::

:::{card} Shima Rastegarnia
:margin: 3
:class-body: text-center
:link: https://github.com/srastegarnia
:img-top: images/profile_shima_rastegarnia.jpg
:::

:::{card} Bertrand Thirion
:margin: 3
:class-body: text-center
:link: https://twitter.com/BertrandThirion
:img-top: images/profile_bertrand.jpg
:::

:::{card} Alexis Thual
:margin: 3
:class-body: text-center
:link: https://twitter.com/alexisthual
:img-top: images/profile_alexis_thual.jpg
:::

::::

**Peer Herholz** is a research affiliate at [The Neuro (Montreal Neurological Institute-Hospital)](https://www.mcgill.ca/neuro/)/[ORIGAMI lab](https://neurodatascience.github.io/) (PI: [Dr. JB Poline](https://www.mcgill.ca/neuro/jean-baptiste-poline-phd)) at [McGill University](https://www.mcgill.ca/) and the [McGovern Institute for Brain Research](https://mcgovern.mit.edu/)/[Senseable Intelligence Group](https://sensein.group/) (PI: [Satra Ghosh](https://satra.cogitatum.org/)). He obtained his PhD in cognitive & computational neuroscience, focusing on auditory processing in humans and machines. Afterwards, he conducted multiple postdocs further working at the intersection between neuroscience & artificial intelligence, as well as expanding the integration of open & reproducible scientific practices therein. Currently, he is working on research questions related to generalization in biological and artificial neural networks, comparing respective representations and their underlying computation.

**Shima Rastegarnia** obtained her Master’s in Computer Science from Montreal university. She completed her Master's at the CRUIGM CNeuroMod project under the supervision of Dr. Pierre Bellec. Her research work focuses on implementing machine learning and deep learning models for brain decoding using functional magnetic resonance imaging datasets.

**Alexis Thual** is a PhD student working at Neurospin CEA and Inria (France). His work focuses on building open-source tools to efficiently compute comparisons between brains although their anatomy and activation patterns are very different across individuals. In particular, his methods can be used to draw comparisons between human and non-human primates. He is also a core-developer of Nilearn.

**Bertrand Thirion** is senior researcher in the MIND team, part of Inria research institute, Saclay, France, that develops statistics and machine learning techniques for brain imaging. He contributes both algorithms and software, with a special focus on functional neuroimaging applications. He is involved in the Neurospin, CEA neuroimaging center, one of the leading high-field MRI for brain imaging places. From 2018 to 2021, Bertrand Thirion has been the head of the DATAIA Institute that federates research on AI, data science and their societal impact in Paris-Saclay University. In 2020, he has recently been appointed as member of the expert committee in charge of advising the government during the Covid-19 pandemic. In 2021, he has become the Head of science (délégué scientifique) of the Inria Saclay-Île-de-France research center. Bertrand Thirion is PI of the [Karaib AI Chair](http://project.inria.fr/karaib) of the [Individual Brain Charting](http://project.inria.fr/ibc) project.

### Objectives 📍
 * Understand the core aspects & principles of `brain decoding`
   - including `dataset` requirements
 * Explore different `decoding models` that can be applied to `brain data`
   - `Support Vector Machines` (`SVM`s)
   - `Multilayer Perceptrons` (`MLP`s)
   - `Graph-Convolutional Neural Networks` (`GCN`s)
 * Get first hands-on experience using the respective `python` `libraries`

### Questions you will be able to answer after taking this module 🎯
  * What does `brain decoding` entail?
  * What kind of `data` and `information` is required for `brain decoding` analyses?
  * What are examples of suitable `decoding models` and what do they comprise?

### Materials

::::{card-carousel} 4
:::{card}
:margin: 3
:class-body: text-center
:class-header: bg-light text-center
:link: https://youtu.be/Eem-OxkvTCc
**Video of this session (Part 1)**
^^^
```{image} images/logo_youtube.png
:height: 100
```
+++
Get to the session {fas}`arrow-right`
:::

:::{card}
:margin: 3
:class-body: text-center
:class-header: bg-light text-center
:link: https://youtu.be/eN5OPMh5PIA
**Video of this session (Part 2)**
^^^
```{image} images/logo_youtube.png
:height: 100
```
+++
Get to the session {fas}`arrow-right`
:::

:::{card}
:margin: 3
:class-body: text-center
:class-header: bg-light text-center
:link: https://main-educational.github.io/brain_encoding_decoding
**The Jupyter Book of this session**
^^^
```{image} images/logo_neurolibre.png
:height: 100
```

Explore and follow the session via `Jupyter Book`.
+++
Get to the session {fas}`arrow-right`
:::

:::{card}
:margin: 3
:class-body: text-center
:class-header: bg-light text-center
:link: https://github.com/main-educational/brain_encoding_decoding

**The session's GitHub repository**
^^^
```{image} https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png
:height: 100
```

Check out the session's materials on `GitHub`.
+++
Explore the `GitHub` repository {fas}`arrow-right`
:::
::::

## Brain encoding
### Instructors
::::{card-carousel} 3
:::{card} Isil Bilgin
:margin: 3
:class-body: text-center
:link: https://github.com/complexbrains
:img-top: images/isil_bilgin.jpg
:::

:::{card} Alexandre Pasquiou
:margin: 3
:class-body: text-center
:link: https://twitter.com/a_pasquiou
:img-top: images/profile_alexandre_pasquiou.jpg
:::

:::{card} Pravish Sainath
:margin: 3
:class-body: text-center
:link: https://github.com/pravishsainath
:img-top: https://avatars.githubusercontent.com/u/13696562?v=4
:::
::::



**Isil Poyraz Bilgin** is a Postdoctoral research fellow at the [CRUIGM](https://criugm.qc.ca/en/) [CNeuroMod](https://www.cneuromod.ca/) project and is supervised by [Prof. Leila Wehbe](https://www.cs.cmu.edu/~lwehbe/) and [Prof. Pierre Bellec](https://simexp.github.io/lab-website/team.html#:~:text=THE%20SIMEXP%20TEAM-,Pierre%20Bellec%2C%20PhD,-%2C%20is%20the). Her work focuses on implementing encoding models to predict brain activities of processing the natural language using representations extracted from natural language models. Her main interest lies in developing optimizations to improve the predictive performance of the neural networks of language models with well-defined features of brain dynamics in processing naturalistic stimuli. She holds a bachelor's degree in pure mathematics and Ph.D. in Cybernetics. Her thesis work focuses on dynamic functional connectivity of the emergence of the neural representation of the novel semantic concepts in the human brain using simultaneous EEG and fMRI.

**Alexandre Pasquiou** is a PhD student working at [INRIA MIND](https://team.inria.fr/mind/) team, with [Christophe Pallier](https://www.pallier.org/) and [Bertrand Thirion](https://pages.saclay.inria.fr/bertrand.thirion/). His work focuses on understanding how the brain processes language. Being an engineer from [CentraleSupélec](https://www.centralesupelec.fr/) (specialized in applied mathematics), he uses machine learning models to dive deeply into the neural bases of language comprehension relying on both encoding and decoding experimental paradigms. Some of his work studied semantic and syntactic processing, the integration of contextual information as well as the pitfalls of encoding models that leveraged features derived from neural language models.


### Objectives
In the first part of the session we will focus on
  * Understanding the foundations of `brain endecoding` with;
     - Preparation of the `fMRI and stimuli dataset`
     - Building encoding models using `ridge regression` to extract direct representation of visual stimuli
     - Evaluation of the model performance using `cross validation`
     - Visualisation of the encoding scores on `cortex`

In the second part of the session we will dive into the predictive `brain encoding` models to
  * Understand the utilization of the high-dimensional stimuli features in `brain encoding` models
  * Explore `brain encoding` of processing the naturalistic stimuli (movie watching) by utilizing
     - `Textual features` extracted with pretrained `BERT` language model
     - `Audio features` extracted with `MFCC (Mel Frequency Cepstral Coefficients)` technique
     - `Audio features` extracted with `ResNet-50` model
     -
  in `ridge regression` models to predict the brain representations.
  * Visualize the prediction accuracy in the cortex brain maps


### Questions you will be able to answer after taking this module 🎯
  * What are the constituents of the `brain encoding`?
  * How `deep learning` models could utilize rich features of the `naturalistic stimuli` in the analysis of `brain encoding`?
  * How the trained `brain encoding` models could generalize to new brain data for  different feature spaces?


### Materials

::::{card-carousel} 3

:::{card}
:margin: 3
:class-body: text-center
:class-header: bg-light text-center
:link: https://github.com/AlexandrePsq/main_tutorial
**The session's repository**
^^^
```{image} https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png
:height: 100
```

Check out the session's materials on `GitHub`.
+++
Explore {fas}`arrow-right`
:::


:::{card}
:margin: 3
:class-body: text-center
:class-header: bg-light text-center
:link: https://main-educational.github.io/brain_encoding_decoding/intro.html
**The Jupyter Book of this session**
^^^
```{image} images/logo_neurolibre.png
:height: 100
```

Check out the session's materials on `GitHub`.
+++
Explore {fas}`arrow-right`
:::
::::
